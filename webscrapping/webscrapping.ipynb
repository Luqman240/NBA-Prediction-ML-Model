{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d019619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import asyncio\n",
    "import requests\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "SEASONS = range(2014,2024)\n",
    "STANDINGS_DIR = os.path.join(DATA_DIR, 'standings')\n",
    "SCORES_DIR = os.path.join(DATA_DIR, 'scores')\n",
    "BASE_URL = 'https://www.basketball-reference.com/'\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2b6be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(2014, 2024)\n"
     ]
    }
   ],
   "source": [
    "print(SEASONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ee7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET HTML ELEMENTS BY THEIR SELECTORS\n",
    "def get_html(url, selector, duration=5, retries=3):\n",
    "    html = None\n",
    "    \n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(duration * i)\n",
    "        try:\n",
    "            browser = webdriver.Chrome()\n",
    "            browser.get(url)  # Utilisez browser.get(url) pour accéder à l'URL\n",
    "            print(browser.title)\n",
    "            elements = browser.find_elements(By.CSS_SELECTOR,selector)\n",
    "            html = [element.get_attribute(\"innerHTML\") for element in elements]\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {i}: {str(e)}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "        finally:\n",
    "            browser.quit()\n",
    "        \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5988abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "#Get all season period link\n",
    "filter_links = {}\n",
    "for season in SEASONS:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    filter_elements = get_html(url, '.filter', 5,3)\n",
    "    soup = BeautifulSoup(('').join(filter_elements), 'html.parser')\n",
    "    #print(soup)\n",
    "    links = [link.get('href') for link in soup.find_all(\"a\")]\n",
    "    #print(links)\n",
    "    filter_links[season] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4dab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_score_links = {}\n",
    "def get_box_scores(links):\n",
    "    if(not os.path.exists(f\"./BOXSCORES\")):\n",
    "        os.makedirs(f\"./BOXSCORES\")\n",
    "    for season in SEASONS:\n",
    "        file_path = f\"./BOXSCORES/BOXSCORES_{season}.txt\"\n",
    "        if os.path.exists(file_path):\n",
    "            continue\n",
    "        box_score_links[season] = []\n",
    "        for link in filter_links[season]:\n",
    "            box_scores = get_html(BASE_URL+link, '[data-stat=\"box_score_text\"]')\n",
    "            soup = BeautifulSoup(''.join(box_scores), 'html.parser')\n",
    "            box_score_links[season] = box_score_links[season] + [element.get('href') for element in soup.find_all('a')]\n",
    "        with open(file_path, 'w') as file:\n",
    "        # Loop through the list and write each string to the file\n",
    "            for string in box_score_links[season]:\n",
    "                file.write(string + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbded496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2013-14 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2014-15 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2015-16 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2016-17 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2017-18 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2018-19 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2019-20 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2020-21 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2021-22 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "get_box_scores(filter_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7418eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_from_value(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    # If the value is not found, you can handle it as needed, e.g., return None or raise an exception.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad0c5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAMS = {\n",
    "    \"ATL\": 0,\n",
    "    \"BOS\": 1,\n",
    "    \"BKN\": 2,\n",
    "    \"CHA\": 3,\n",
    "    \"CHI\": 4,\n",
    "    \"CLE\": 5,\n",
    "    \"DAL\": 6,\n",
    "    \"DEN\": 7,\n",
    "    \"DET\": 8,\n",
    "    \"GSW\": 9,\n",
    "    \"HOU\": 10,\n",
    "    \"IND\": 11,\n",
    "    \"LAC\": 12,\n",
    "    \"LAL\": 13,\n",
    "    \"MEM\": 14,\n",
    "    \"MIA\": 15,\n",
    "    \"MIL\": 16,\n",
    "    \"MIN\": 17,\n",
    "    \"NOP\": 18,\n",
    "    \"NYK\": 19,\n",
    "    \"OKC\": 20,\n",
    "    \"ORL\": 21,\n",
    "    \"PHI\": 22,\n",
    "    \"PHX\": 23,\n",
    "    \"POR\": 24,\n",
    "    \"SAC\": 25,\n",
    "    \"SAS\": 26,\n",
    "    \"TOR\": 27,\n",
    "    \"UTA\": 28,\n",
    "    \"WAS\": 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f033f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf91fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_nan(df):\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i])):\n",
    "            if(df.iloc[i,j] == \"Did Not Play\" or df.iloc[i,j] == \"Did Not Dress\" or df.iloc[i,j] == \"Not With Team\"):\n",
    "                df.iloc[i,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf383b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Line Score Table to get the name of team\n",
    "def get_team_df(link):\n",
    "    line_score = get_html(BASE_URL+link, \"[id='div_line_score']\")\n",
    "    soup_line_score = BeautifulSoup(line_score[0], 'html.parser')\n",
    "    line_score_table = soup_line_score.find('table')\n",
    "    pd_line_score = pd.read_html(StringIO(line_score_table.prettify()))\n",
    "    line_score_df = pd_line_score[0]\n",
    "    team_names = np.array(line_score_df.iloc[:,0])\n",
    "    line_score_df\n",
    "    won = False\n",
    "    if(int(line_score_df.iloc[0, -1]) > int(line_score_df.iloc[1,-1])):\n",
    "        won = True\n",
    "    else:\n",
    "        won = False\n",
    "\n",
    "    team_names = np.append(team_names,won)\n",
    "    team_names = team_names.reshape(1, -1)\n",
    "    team_names_header = ['TEAM', 'TEAM_OPP', 'WON']\n",
    "    team_row = pd.DataFrame(team_names, columns=team_names_header)\n",
    "    return team_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a758613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = [line.strip() for line in file.readlines()]\n",
    "        return lines\n",
    "\n",
    "def dataframe_processing(df):\n",
    "    str_to_nan(df)\n",
    "    df = df.drop(5)\n",
    "    df = df.sort_index(axis=1)\n",
    "    df.pop(df.columns[-1])\n",
    "    df.pop(df.columns[0])\n",
    "    column_names = [t[1] for t in df.columns]\n",
    "    max_column_names = [c+'_MAX' for c in column_names]\n",
    "    column_names += max_column_names\n",
    "    values = np.array(df.iloc[-1])\n",
    "    df.drop(df.tail(1).index,inplace=True)\n",
    "    return df, values\n",
    "\n",
    "\n",
    "\n",
    "def add_max_values(df):\n",
    "    temp_df = df\n",
    "    temp_df = temp_df.apply(pd.to_numeric, errors='coerce')\n",
    "    #Delete rows with only NAN values\n",
    "    temp_df = temp_df.dropna(axis=1, how='all')\n",
    "    #print(temp_df)\n",
    "    values = np.nanmax(temp_df, axis=0)\n",
    "    return values\n",
    "\n",
    "def get_header(df):\n",
    "    headers = [t[1] for t in df.columns]\n",
    "    return headers\n",
    "\n",
    "def get_max_header(df):\n",
    "    headers = []\n",
    "    for t in df.columns:\n",
    "        s = t[1] +'_MAX'\n",
    "        headers.append(s)\n",
    "    headers.pop(13)\n",
    "    return headers\n",
    "\n",
    "def get_opp_header(df):\n",
    "    headers = ['OPP_'+t[1] for t in df.columns]\n",
    "    return headers\n",
    "\n",
    "def get_opp_max_header(df):\n",
    "    headers = []\n",
    "    for t in df.columns:\n",
    "        s = 'OPP_'+t[1] +'_MAX'\n",
    "        headers.append(s)\n",
    "    headers.pop(13)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050780c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_html_files(season):\n",
    "    if(not os.path.exists(\"./HTML_FILES\")):\n",
    "        os.makedirs(f\"./HTML_FILES\")\n",
    "    print(f\"!!! DOWNLOADING SEASON {season} !!!\")\n",
    "    time.sleep(10)\n",
    "    if(not os.path.exists(f\"./HTML_FILES/{season}\")):\n",
    "        os.makedirs(f\"./HTML_FILES/{season}\")\n",
    "    boxscore_links = get_links_from_file(f'BOXSCORES/BOXSCORES_{season}.txt')\n",
    "    for j in range(len(boxscore_links)):\n",
    "        temp_link = boxscore_links[j].replace(\"/boxscores/\", \"\")\n",
    "        filename = temp_link.replace(\".html\", \"\")\n",
    "        if(os.path.exists(f\"./HTML_FILES/{season}/{filename}.html\")):\n",
    "            print(\"existe deja\")\n",
    "            continue\n",
    "        time.sleep(2)\n",
    "        response = requests.get(BASE_URL + boxscore_links[j])\n",
    "        with open(f\"./HTML_FILES/{season}/{filename}.html\", 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "def get_dataframes():\n",
    "    all_dataframes = {key:None for key in SEASONS}\n",
    "    \n",
    "    for season in SEASONS:\n",
    "        if os.path.exists(f\"../DATAS/season_{season}.xlsx\"):\n",
    "            continue\n",
    "        print(f\"Start generating dataframe for season {season}...\")\n",
    "        season_dataframe = pd.DataFrame()\n",
    "        \"\"\"-------------- GET TABLE IN PAGE --------------\"\"\"\n",
    "        directory_path = f\"./HTML_FILES/{season}/\"\n",
    "        \n",
    "        filenames = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "        for filename in filenames:\n",
    "            with open(directory_path+filename, 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "\n",
    "            page = BeautifulSoup(html_content, 'html.parser')\n",
    "            score_tables = page.find_all(\"table\",id=lambda value: value and 'box-' in value and '-game-basic' in value)\n",
    "            if(len(score_tables) != 2):\n",
    "                continue\n",
    "\n",
    "            table = pd.read_html(StringIO(score_tables[0].prettify()))[0]\n",
    "            opp_table = pd.read_html(StringIO(score_tables[1].prettify()))[0]\n",
    "\n",
    "            #GET DATAFRAMES\n",
    "            df, row_values = dataframe_processing(table)\n",
    "            opp_df, opp_row_values = dataframe_processing(opp_table)\n",
    "\n",
    "            \"\"\"-------------- MATCH DATAS --------------\"\"\"\n",
    "            #FIRST TEAM\n",
    "            max_values = add_max_values(df)\n",
    "            header = get_header(df)\n",
    "            max_header = get_max_header(df)\n",
    "            max_values = max_values.reshape(1, -1)\n",
    "            row_values = row_values.reshape(1, -1)\n",
    "\n",
    "            row = pd.DataFrame(row_values, columns=header)\n",
    "            max_row = pd.DataFrame(max_values, columns=max_header)\n",
    "\n",
    "            #OPP TEAM\n",
    "            opp_max_values = add_max_values(opp_df)\n",
    "            opp_header = get_opp_header(opp_df)\n",
    "            opp_max_header = get_opp_max_header(opp_df)\n",
    "            opp_max_values = opp_max_values.reshape(1, -1)\n",
    "            opp_row_values = opp_row_values.reshape(1, -1)\n",
    "\n",
    "            opp_row = pd.DataFrame(opp_row_values, columns=opp_header)\n",
    "            opp_max_row = pd.DataFrame(opp_max_values, columns=opp_max_header)\n",
    "\n",
    "            \"\"\"-------------- TEAMS DATAS --------------\"\"\"\n",
    "            teams = []\n",
    "            #Get team names\n",
    "            for table in score_tables:\n",
    "                id_of_table = table.get('id')\n",
    "                team_name = id_of_table.replace(\"box-\", \"\").replace(\"-game-basic\", \"\")\n",
    "                teams.append(team_name)\n",
    "\n",
    "            #Get won status\n",
    "            team_final_score = row_values[-1, 8]\n",
    "            opp_team_final_score = opp_row_values[-1, 8]\n",
    "            won = int(team_final_score) > int(opp_team_final_score)\n",
    "            teams.append(won)\n",
    "\n",
    "            teams_array = np.array(teams)\n",
    "            teams_array = teams_array.reshape(1, -1)\n",
    "            team_row_header = ['TEAM', 'TEAM_OPP', 'WON']\n",
    "            team_row = pd.DataFrame(teams_array, columns=team_row_header)\n",
    "\n",
    "            #Create full row with all the datas\n",
    "            full_row = pd.concat([row,opp_row,max_row,opp_max_row,team_row], axis=1)\n",
    "            season_dataframe = pd.concat([season_dataframe, full_row], ignore_index=True)\n",
    "        \n",
    "        print(f\"Dataframe for season {season} done !!!\")\n",
    "        export_dataframe(season_dataframe, season)\n",
    "\n",
    "def export_dataframe(df, season):\n",
    "    if(not os.path.exists(f\"../DATAS\")):\n",
    "        os.makedirs(f\"../DATAS\")\n",
    "    if os.path.exists(f\"../DATAS/season_{season}.xlsx\"):\n",
    "        return\n",
    "    df.to_excel(f'../DATAS/season_{season}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1cdcd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating dataframe for season 2020...\n",
      "Dataframe for season 2020 done !!!\n",
      "Start generating dataframe for season 2021...\n",
      "Dataframe for season 2021 done !!!\n",
      "Start generating dataframe for season 2022...\n",
      "Dataframe for season 2022 done !!!\n",
      "Start generating dataframe for season 2023...\n",
      "Dataframe for season 2023 done !!!\n",
      "ALL DONE !!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2014: None,\n",
       " 2015: None,\n",
       " 2016: None,\n",
       " 2017: None,\n",
       " 2018: None,\n",
       " 2019: None,\n",
       " 2020: None,\n",
       " 2021: None,\n",
       " 2022: None,\n",
       " 2023: None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create and Extract Dataframe to Excel\n",
    "get_dataframes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
